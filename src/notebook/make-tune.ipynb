{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 10826208,
     "sourceType": "datasetVersion",
     "datasetId": 6722562
    }
   ],
   "dockerImageVersionId": 30919,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T01:00:16.673413Z",
     "start_time": "2025-02-23T01:00:16.670304Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pickle\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras_tuner as kt"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-23T01:00:15.023422Z",
     "start_time": "2025-02-23T01:00:15.016262Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Dense, Dropout, BatchNormalization\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import (\n",
    "    ModelCheckpoint, EarlyStopping\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%run make_datasets.ipynb\n",
    "%run make_embeddings.ipynb"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('../data/df.csv')\n",
    "df.dropna(inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "print(df.shape)\n",
    "df.head()"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-22T22:06:43.918326Z",
     "iopub.execute_input": "2025-02-22T22:06:43.918678Z",
     "iopub.status.idle": "2025-02-22T22:06:43.973797Z",
     "shell.execute_reply.started": "2025-02-22T22:06:43.918652Z",
     "shell.execute_reply": "2025-02-22T22:06:43.972936Z"
    },
    "ExecuteTime": {
     "end_time": "2025-02-23T00:44:53.217270Z",
     "start_time": "2025-02-23T00:44:53.178476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6867, 5)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                        name  price             category  \\\n",
       "0  cimento forte multiuso cpii cimento forte  34.89  argamassas_rejuntes   \n",
       "1                  po de brita saco granumix   7.90  argamassas_rejuntes   \n",
       "2             areia vegetal saco granumix av   9.90  argamassas_rejuntes   \n",
       "3      areia industrial grossa saco granumix   9.90  argamassas_rejuntes   \n",
       "4                    saibro saco granumix sb   7.90  argamassas_rejuntes   \n",
       "\n",
       "           brand  target  \n",
       "0  CIMENTO FORTE       7  \n",
       "1       GRANUMIX       7  \n",
       "2       GRANUMIX       7  \n",
       "3       GRANUMIX       7  \n",
       "4       GRANUMIX       7  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>price</th>\n",
       "      <th>category</th>\n",
       "      <th>brand</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cimento forte multiuso cpii cimento forte</td>\n",
       "      <td>34.89</td>\n",
       "      <td>argamassas_rejuntes</td>\n",
       "      <td>CIMENTO FORTE</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>po de brita saco granumix</td>\n",
       "      <td>7.90</td>\n",
       "      <td>argamassas_rejuntes</td>\n",
       "      <td>GRANUMIX</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>areia vegetal saco granumix av</td>\n",
       "      <td>9.90</td>\n",
       "      <td>argamassas_rejuntes</td>\n",
       "      <td>GRANUMIX</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>areia industrial grossa saco granumix</td>\n",
       "      <td>9.90</td>\n",
       "      <td>argamassas_rejuntes</td>\n",
       "      <td>GRANUMIX</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saibro saco granumix sb</td>\n",
       "      <td>7.90</td>\n",
       "      <td>argamassas_rejuntes</td>\n",
       "      <td>GRANUMIX</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "train, test, valid = split_data(df)\n",
    "embed_dim = 512\n",
    "print(train.shape, test.shape, valid.shape)"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-22T22:07:21.740845Z",
     "iopub.execute_input": "2025-02-22T22:07:21.741124Z",
     "iopub.status.idle": "2025-02-22T22:07:21.760677Z",
     "shell.execute_reply.started": "2025-02-22T22:07:21.741104Z",
     "shell.execute_reply": "2025-02-22T22:07:21.759968Z"
    },
    "ExecuteTime": {
     "end_time": "2025-02-23T00:56:59.181201Z",
     "start_time": "2025-02-23T00:56:59.159913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4119, 5) (1374, 5) (1374, 5)\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": "class L2NormalizeLayer(keras.Layer):\n    def __init__(self, **kwargs):\n        super(L2NormalizeLayer, self).__init__(**kwargs)\n\n    def call(self, inputs):\n        return tf.math.l2_normalize(inputs, axis=1)\n\nclass TripletLossBlock(keras.Layer):\n    def __init__(self, alpha, **kwargs):\n        self.alpha = alpha\n        super(TripletLossBlock, self).__init__(**kwargs)\n    \n    def triplet_loss(self, inputs):\n        a, p, n = inputs\n        p_dist = keras.ops.sum(keras.ops.square(a - p), axis=-1)\n        n_dist = keras.ops.sum(keras.ops.square(a - n), axis=-1)\n        return keras.ops.sum(keras.ops.maximum(p_dist - n_dist + self.alpha, 0), axis=0)\n    \n    def call(self, inputs):\n        loss = self.triplet_loss(inputs)\n        self.add_loss(loss)\n        return loss",
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-22T22:07:57.049434Z",
     "iopub.execute_input": "2025-02-22T22:07:57.049763Z",
     "iopub.status.idle": "2025-02-22T22:07:57.055694Z",
     "shell.execute_reply.started": "2025-02-22T22:07:57.049740Z",
     "shell.execute_reply": "2025-02-22T22:07:57.054903Z"
    },
    "ExecuteTime": {
     "end_time": "2025-02-23T00:57:03.439875Z",
     "start_time": "2025-02-23T00:57:03.421588Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "def build_model(hp):\n",
    "    input_one = Input(shape=(embed_dim,))\n",
    "    \n",
    "    dense1_units = hp.Int('dense1_units', min_value=128, max_value=512, step=64)\n",
    "    dense2_units = hp.Int('dense2_units', min_value=64, max_value=256, step=32)\n",
    "    \n",
    "    x = Dense(units=dense1_units, activation='relu')(input_one)\n",
    "    x = Dropout(hp.Float('dropout1', min_value=0.2, max_value=0.5, step=0.1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Dense(units=dense2_units, activation='relu', \n",
    "              kernel_regularizer=keras.regularizers.l2(hp.Float('l2_reg', min_value=0.001, max_value=0.01, sampling='log')))(x)\n",
    "    x = Dropout(hp.Float('dropout2', min_value=0.2, max_value=0.5, step=0.1))(x)\n",
    "    \n",
    "    dense_layer = Dense(8, name='dense_layer')(x)\n",
    "    norm_layer = L2NormalizeLayer(name='norm_layer')(dense_layer)\n",
    "    \n",
    "    base_model = Model(inputs=input_one, outputs=norm_layer)\n",
    "    \n",
    "    input_a = Input(shape=(embed_dim,))\n",
    "    input_p = Input(shape=(embed_dim,))\n",
    "    input_n = Input(shape=(embed_dim,))\n",
    "    \n",
    "    embed_a = base_model(input_a)\n",
    "    embed_p = base_model(input_p)\n",
    "    embed_n = base_model(input_n)\n",
    "    \n",
    "    alpha = hp.Float('alpha', min_value=0.2, max_value=0.8, step=0.2)\n",
    "    triplet_loss = TripletLossBlock(alpha=alpha, name='triplet_loss_block')([embed_a, embed_p, embed_n])\n",
    "    \n",
    "    snn_model = Model([input_a, input_p, input_n], triplet_loss)\n",
    "    \n",
    "    snn_model.compile(\n",
    "        optimizer=keras.optimizers.Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')),\n",
    "        loss=None\n",
    "    )\n",
    "    \n",
    "    return snn_model\n",
    "\n",
    "tuner = kt.RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_loss',\n",
    "    max_trials=20,\n",
    "    executions_per_trial=1,\n",
    "    directory='hyperparam_tuning_bert',\n",
    "    project_name='siamese_bert_tuning'\n",
    ")\n",
    "\n",
    "tuner.search_space_summary()"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-22T22:08:00.795196Z",
     "iopub.execute_input": "2025-02-22T22:08:00.795482Z",
     "iopub.status.idle": "2025-02-22T22:08:00.869357Z",
     "shell.execute_reply.started": "2025-02-22T22:08:00.795461Z",
     "shell.execute_reply": "2025-02-22T22:08:00.868583Z"
    },
    "ExecuteTime": {
     "end_time": "2025-02-23T00:57:09.439397Z",
     "start_time": "2025-02-23T00:57:09.371635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search space summary\n",
      "Default search space size: 7\n",
      "dense1_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 128, 'max_value': 512, 'step': 64, 'sampling': 'linear'}\n",
      "dense2_units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 256, 'step': 32, 'sampling': 'linear'}\n",
      "dropout1 (Float)\n",
      "{'default': 0.2, 'conditions': [], 'min_value': 0.2, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "l2_reg (Float)\n",
      "{'default': 0.001, 'conditions': [], 'min_value': 0.001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n",
      "dropout2 (Float)\n",
      "{'default': 0.2, 'conditions': [], 'min_value': 0.2, 'max_value': 0.5, 'step': 0.1, 'sampling': 'linear'}\n",
      "alpha (Float)\n",
      "{'default': 0.2, 'conditions': [], 'min_value': 0.2, 'max_value': 0.8, 'step': 0.2, 'sampling': 'linear'}\n",
      "learning_rate (Float)\n",
      "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size, colfeat, collabel = 64, 'name', 'target'\n",
    "dataset_train = create_trip_dtset(batch_size, train.loc[:3], colfeat, collabel, get_use_embed, embed_dim)\n",
    "dataset_val = create_trip_dtset(batch_size, valid.loc[:3], colfeat, collabel, get_use_embed, embed_dim)\n",
    "steps = len(train) // batch_size"
   ],
   "metadata": {
    "trusted": true,
    "execution": {
     "iopub.status.busy": "2025-02-22T22:09:10.181687Z",
     "iopub.execute_input": "2025-02-22T22:09:10.181976Z",
     "iopub.status.idle": "2025-02-22T22:09:10.273948Z",
     "shell.execute_reply.started": "2025-02-22T22:09:10.181957Z",
     "shell.execute_reply": "2025-02-22T22:09:10.272702Z"
    },
    "ExecuteTime": {
     "end_time": "2025-02-23T03:01:57.229539Z",
     "start_time": "2025-02-23T03:01:57.166344Z"
    }
   },
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "source": [
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_bert_siamese_model.keras',\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "tuner.search(\n",
    "    dataset_train,\n",
    "    epochs=20,\n",
    "    steps_per_epoch=steps,\n",
    "    validation_data=dataset_val,\n",
    "    validation_steps=steps,\n",
    "    callbacks=[checkpoint, early_stopping]\n",
    ")"
   ],
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
